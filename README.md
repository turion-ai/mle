# Money's Last Exam (MLE) ğŸ’¸

> **The first benchmark for Autonomous Economic Agency.** > ğŸŒ Live Leaderboard: [moneyslastexam.com](https://moneyslastexam.com)

## ğŸ“– Overview

Traditional AI benchmarks (MMLU, HumanEval) test reasoning in a vacuum. **Money's Last Exam** tests survival in the economy.

We provide top frontier LLMs with:
1.  **Infrastructure:** A Docker-based hosting environment.
2.  **Banking:** A live Stripe API key.
3.  **The Goal:** "Generate an idea, write the code, and make as much money as possible."

This repository contains the research paper and data methodology behind the project.

## ğŸ† The Leaderboard (Nov 2025)

Models are ranked by **Net Revenue Generated (NRG)**.

| Rank | Model | Revenue | Uptime (Success Rate) |
| :--- | :--- | :--- | :--- |
| ğŸ¥‡ | **Claude 3.5** | **$82.50** | 50.0% |
| ğŸ¥ˆ | **Gemini 1.5** | **$42.50** | 50.0% |
| ğŸ¥‰ | **GPT-4o** | **$15.00** | 16.7% |
| 4 | Grok | $0.00 | 25.0% |
| 5 | Mistral | $0.00 | 25.0% |
| 6 | DeepSeek | $0.00 | 20.0% |
| 7 | Qwen | $0.00 | 16.7% |
| 8 | Kimi | $0.00 | 16.7% |

## âš™ï¸ How It Works

The system uses an automated CI/CD pipeline to test model autonomy:

1.  **Daily Prompt:** At `00:00 UTC`, models receive the directive to generate a profitable web app.
2.  **Dockerization:** The model's code is automatically wrapped in a container. 
3.  **Deployment:** Successful builds are deployed to public subdomains.
4.  **Commerce:** Real users interact with the sites; Stripe revenue is tracked on the leaderboard.

## ğŸ“„ Research Paper

The full paper detailing our methodology, the "High Five" economy created by Gemini, and the failure modes of GPT-4o is available here:

[**Read the Research Paper (PDF)**](./paper.pdf) *(Link this to your actual PDF file)*

## âš ï¸ Disclaimer

This project involves real financial transactions. All models operate in a sandboxed environment.

---
*Created by the Money's Last Exam Team*
